{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'book']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'this is a book'\n",
    "a.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/46/b7dzk4mn6g54qzptv608w7d00000gn/T/jieba.cache\n",
      "Loading model cost 0.781 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['那', '酸民', '婉君', '也', '可以', '報名', '嗎', '?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "seg = jieba.cut('那酸民婉君也可以報名嗎?')\n",
    "list(seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas\n",
    "news = pandas.read_excel('https://raw.githubusercontent.com/ywchiu/pytextmining/master/data/20150628news.xlsx', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>社會/生活</td>\n",
       "      <td>新北市八仙水上樂園昨晚發生粉塵爆炸，新北市衛生局統計到目前為止，由救護車送醫再加上自行送醫的...</td>\n",
       "      <td>Sun, 28 Jun 2015 07:40:00 +0800</td>\n",
       "      <td>八仙塵爆  五相關人依公共危險重傷害法辦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>社會/生活</td>\n",
       "      <td>新北市八仙樂園昨天晚上(6/27)舉辦活動，過程中噴灑大量玉米粉而引發粉塵爆炸，根據最新統計...</td>\n",
       "      <td>Sun, 28 Jun 2015 07:40:00 +0800</td>\n",
       "      <td>八仙樂園意外 病患持續增加中</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>財經/要聞</td>\n",
       "      <td>希臘債務違約限期逼近，資金持續外流。路透社引述三間銀行的消息指出，希臘國內有3分之1的自動櫃...</td>\n",
       "      <td>Sun, 28 Jun 2015 07:40:00 +0800</td>\n",
       "      <td>希臘國內三分一自動櫃員機現金短缺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>社會/生活</td>\n",
       "      <td>台鐵「新基隆車站」第一階段工程本月底完成，台鐵表示，明天（29號）啟用後，由於南站周邊道路尚...</td>\n",
       "      <td>Sun, 28 Jun 2015 07:40:00 +0800</td>\n",
       "      <td>台鐵新基隆車站29日正式啟用</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>財經/要聞</td>\n",
       "      <td>《中國時報》\\n●樂園變煉獄 派對驚爆 逾300人遭火紋身\\n八仙樂園昨晚舉辦「COLOR ...</td>\n",
       "      <td>Sun, 28 Jun 2015 07:38:17 +0800</td>\n",
       "      <td>6月28日各報頭版要聞</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                        description  \\\n",
       "0    社會/生活  新北市八仙水上樂園昨晚發生粉塵爆炸，新北市衛生局統計到目前為止，由救護車送醫再加上自行送醫的...   \n",
       "1    社會/生活  新北市八仙樂園昨天晚上(6/27)舉辦活動，過程中噴灑大量玉米粉而引發粉塵爆炸，根據最新統計...   \n",
       "2    財經/要聞  希臘債務違約限期逼近，資金持續外流。路透社引述三間銀行的消息指出，希臘國內有3分之1的自動櫃...   \n",
       "3    社會/生活  台鐵「新基隆車站」第一階段工程本月底完成，台鐵表示，明天（29號）啟用後，由於南站周邊道路尚...   \n",
       "4    財經/要聞  《中國時報》\\n●樂園變煉獄 派對驚爆 逾300人遭火紋身\\n八仙樂園昨晚舉辦「COLOR ...   \n",
       "\n",
       "                           pubdate                 title  \n",
       "0  Sun, 28 Jun 2015 07:40:00 +0800  八仙塵爆  五相關人依公共危險重傷害法辦  \n",
       "1  Sun, 28 Jun 2015 07:40:00 +0800        八仙樂園意外 病患持續增加中  \n",
       "2  Sun, 28 Jun 2015 07:40:00 +0800      希臘國內三分一自動櫃員機現金短缺  \n",
       "3  Sun, 28 Jun 2015 07:40:00 +0800        台鐵新基隆車站29日正式啟用  \n",
       "4  Sun, 28 Jun 2015 07:38:17 +0800           6月28日各報頭版要聞  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "#jieba.load_userdict('userdict.txt')\n",
    "\n",
    "titles = []\n",
    "corpus = []\n",
    "for rec in news.iterrows():\n",
    "    titles.append(rec[1].title)\n",
    "    corpus.append(' '.join(jieba.cut(rec[1].description)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 11138)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "n_cosine_similarities  = cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "km = cluster.KMeans(n_clusters=4, init='k-means++', random_state=42)\n",
    "c = km.fit_predict(n_cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "np_titles = numpy.array(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "希臘國內三分一自動櫃員機現金短缺\n",
      "歐元區財長拒希臘延長救助計劃\n",
      "呂紹煒專欄：違約與退出 希臘與歐洲才能重生(上)\n",
      "希臘違約在即  歐盟全力穩定經濟\n",
      "希臘脫歐變可能 歐洲衝擊大\n",
      "希債協議  法國願盡最後斡旋努力\n",
      "希臘1／3提款機錢被提光\n",
      "確保銀行穩定 希臘續與ECB緊密合作\n",
      "希臘態度強硬 歐元區耐心漸失\n",
      "希臘盼展延債務 歐元區拒絕\n"
     ]
    }
   ],
   "source": [
    "for t in np_titles[c == 3]:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "news = pandas.read_excel('https://raw.githubusercontent.com/ywchiu/pytextmining/master/data/20171214news.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "生活      160\n",
       "社會      146\n",
       "國際      127\n",
       "財經地產    110\n",
       "娛樂      101\n",
       "政治       84\n",
       "體育       62\n",
       "論壇       38\n",
       "副刊       25\n",
       "3C       22\n",
       "動物       19\n",
       "壹週刊       5\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "titles = []\n",
    "tags   = []\n",
    "for rec in news[news['category'].isin(['社會','娛樂'])].iterrows():\n",
    "    tags.append(rec[1]['category'])\n",
    "    titles.append(rec[1]['title'])\n",
    "    corpus.append(' '.join(jieba.cut(rec[1]['content'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<247x11380 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 30778 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_data, test_data, train_tag, test_tag, train_title, test_title = train_test_split(X, tags, titles, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha=0.01)\n",
    "clf.fit(train_data,train_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_tag == predicted) / len(test_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['娛樂' '社會']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32,  0],\n",
       "       [ 1, 42]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(clf.classes_)\n",
    "confusion_matrix(test_tag, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65.0, '男子', 0.0, 65.0)\n",
      "(48.0, '警員', 0.0, 48.0)\n",
      "(38.0, '突發', 0.0, 38.0)\n",
      "(36.0, '新北', 0.0, 36.0)\n",
      "(36.0, '機車', 0.0, 36.0)\n",
      "(34.0, '江男', 0.0, 34.0)\n",
      "(32.0, '進行', 0.0, 32.0)\n",
      "(31.0, '法官', 0.0, 31.0)\n",
      "(30.4, '警方', 4.0, 152.0)\n",
      "(30.0, '少年', 0.0, 30.0)\n",
      "(30.0, '張男', 0.0, 30.0)\n",
      "(30.0, '派出所', 0.0, 30.0)\n",
      "(29.0, '陳姓', 0.0, 29.0)\n",
      "(29.0, '陳男', 0.0, 29.0)\n",
      "(27.0, '林男', 0.0, 27.0)\n",
      "(24.0, '時許', 0.0, 24.0)\n",
      "(24.0, '檢方', 0.0, 24.0)\n",
      "(24.0, '警察', 0.0, 24.0)\n",
      "(23.5, '律師', 1.0, 47.0)\n",
      "(23.0, '法院', 0.0, 23.0)\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "coef_features_c1_c2 = []\n",
    "\n",
    "for index, features in enumerate(zip(vectorizer.get_feature_names(), \\\n",
    "                        clf.feature_count_[0], clf.feature_count_[1])):\n",
    "    feat,c1,c2 = features\n",
    "    coef_features_c1_c2.append(tuple([c2/(c1 + 1), feat, c1, c2]))\n",
    "\n",
    "for i in sorted(coef_features_c1_c2, key = operator.itemgetter(0), reverse=True)[0:20]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "movies  = pandas.read_excel('https://raw.githubusercontent.com/ywchiu/pytextmining/master/data/yahoo_movie.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "最終騎士       452\n",
       "奧創紀元       281\n",
       "攻殼機動隊      173\n",
       "最後的絕地武士    117\n",
       "古墓奇兵        89\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies[movies['status'] != 'soso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "#jieba.load_userdict('userdict.txt')\n",
    "corpus = []\n",
    "scores = []\n",
    "for movie in movies.iterrows():\n",
    "    corpus.append(' '.join(jieba.cut(movie[1].content)))\n",
    "    scores.append(movie[1].status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<980x4839 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16211 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, scores, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha = 0.01)\n",
    "clf.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7687074829931972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "predicted = clf.predict(test_X)\n",
    "\n",
    "print(accuracy_score(test_Y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad' 'good']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 82,  35],\n",
       "       [ 33, 144]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clf.classes_)\n",
    "confusion_matrix(test_Y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6.178434271448121, '不錯', 1.0217256810242579, 12.491099235107066)\n",
      "(4.841496524639071, '好看', 5.721890998280063, 32.54401190717558)\n",
      "(3.268002598004482, '非常', 0.8762828650075458, 6.131697277435952)\n",
      "(3.113001433356311, '希望', 0.0, 3.113001433356311)\n",
      "(3.0247294973540355, '雖然', 0.7251698131544237, 5.2181720217929355)\n",
      "(2.611183199778206, '感動', 0.0, 2.611183199778206)\n",
      "(2.571315326386349, '不過', 0.6261452957600632, 4.181332321918913)\n",
      "(2.5367443211815166, '值得', 1.055760159296236, 5.214937909805936)\n",
      "(2.472482266378667, '大家', 0.7358643195575264, 4.291893746945456)\n",
      "(2.4505531251249275, '刺激', 0.4969358919588743, 3.6683209281514904)\n",
      "(2.390246731027003, '其實', 0.627292613286546, 3.889630849332555)\n",
      "(2.279531356498127, '爽片', 1.7571929836326827, 6.285107862107328)\n",
      "(2.248390413545918, '有些', 0.33777782660848044, 3.0078468408008003)\n",
      "(2.2296991856156567, '效果', 0.0, 2.2296991856156567)\n",
      "(2.22153269208444, '但是', 0.7678723366638398, 3.927386191330429)\n",
      "(2.2140501262756667, '喜歡', 1.0301665906033628, 4.494890596286016)\n",
      "(2.1315715690916055, '很爽', 0.2765606570396251, 2.7210804027665643)\n",
      "(2.127164540463352, '期待', 1.4077242532420837, 5.121625654710164)\n",
      "(2.103745389034346, '精彩', 0.972768622869756, 4.150202893993886)\n",
      "(2.086083952757553, '還可以', 0.9163375941464995, 3.997641103215029)\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "coef_features_c1_c2 = []\n",
    "\n",
    "for index, features in enumerate(zip(vectorizer.get_feature_names(), \\\n",
    "                        clf.feature_count_[0], clf.feature_count_[1])):\n",
    "    feat,c1,c2 = features\n",
    "    coef_features_c1_c2.append(tuple([c2/(c1 + 1), feat, c1, c2]))\n",
    "\n",
    "for i in sorted(coef_features_c1_c2, key = operator.itemgetter(0), reverse=True)[0:20]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
